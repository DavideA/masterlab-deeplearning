{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_sequence_counter.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "meRdpqkCyCAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import proper packages"
      ]
    },
    {
      "metadata": {
        "id": "-0MsSZCyvMJD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from os import makedirs\n",
        "from os.path import exists\n",
        "from os.path import dirname\n",
        "from random import shuffle\n",
        "\n",
        "epsilon = np.finfo(float).eps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HNMAxPJbyFQX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This class models the dataset used for today's lecture: each example is composed of binary sequences, and the target variable encodes how many \"1\" there are within each sequence."
      ]
    },
    {
      "metadata": {
        "id": "M7FNirv1vYhH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SyntheticSequenceDataset:\n",
        "\n",
        "    def __init__(self, max_sequence_length=20, dataset_cache='data/synthetic_dataset.pickle', force_recompute=False):\n",
        "\n",
        "        self._data = None\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.force_recompute = force_recompute\n",
        "        self.dataset_cache = dataset_cache\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "\n",
        "        if not self._data:\n",
        "            if not self.force_recompute and exists(self.dataset_cache):\n",
        "                print('Loading dataset from cache...')\n",
        "                with open(self.dataset_cache, 'rb') as dump_file:\n",
        "                    dataset = pickle.load(dump_file)\n",
        "            else:\n",
        "                print('Recomputing dataset...')\n",
        "                dataset = self._compute_dataset()\n",
        "                if not exists(dirname(self.dataset_cache)):\n",
        "                    makedirs(dirname(self.dataset_cache))\n",
        "                with open(self.dataset_cache, 'wb') as dump_file:\n",
        "                    pickle.dump(dataset, dump_file)\n",
        "\n",
        "            # Store data\n",
        "            self._data = dataset\n",
        "\n",
        "        return self._data\n",
        "\n",
        "    def _compute_dataset(self,):\n",
        "\n",
        "        n = self.max_sequence_length\n",
        "        num_examples = 2 ** n\n",
        "        num_classes = n + 1\n",
        "\n",
        "        # How many examples to use for training (others are for test)\n",
        "        num_train_examples = int(0.8 * num_examples)\n",
        "\n",
        "        # Generate 2**20 binary strings\n",
        "        data_strings = [('{' + '0:0{}b'.format(n) + '}').format(i) for i in range(num_examples)]\n",
        "\n",
        "        # Shuffle sequences\n",
        "        shuffle(data_strings)\n",
        "\n",
        "        # Cast to numeric each generated binary string\n",
        "        data_x, data_y = [], []\n",
        "        for i in range(num_examples):\n",
        "            train_sequence = []\n",
        "            for binary_char in data_strings[i]:\n",
        "                value = int(binary_char)\n",
        "                train_sequence.append([value])\n",
        "            data_x.append(train_sequence)           # examples are binary sequences of int {0, 1}\n",
        "            data_y.append(np.sum(train_sequence))   # targets are the number of ones in the sequence\n",
        "\n",
        "        # Convert from categorical to one-hot\n",
        "        data_y_one_hot = np.eye(num_classes)[data_y]\n",
        "\n",
        "        # Separate suggested training and test data\n",
        "        train_data      = data_x[:num_train_examples]\n",
        "        train_targets   = data_y_one_hot[:num_train_examples]\n",
        "        test_data       = data_x[num_train_examples:]\n",
        "        test_targets    = data_y_one_hot[num_train_examples:]\n",
        "\n",
        "        return train_data, train_targets, test_data, test_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSb8xepsybJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This class represents our recurrent module for learning to count. Your job is to fill in all the methods building the graph for inference, loss function, train step.\n",
        "You may find [tf.contrib.rnn.LSTMCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell), [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn), [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense) useful"
      ]
    },
    {
      "metadata": {
        "id": "kTDWoQaSvdSe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DeepCounter:\n",
        "\n",
        "    def __init__(self, x, targets, hidden_size):\n",
        "\n",
        "        self.x = x\n",
        "        self.targets = targets\n",
        "        self.n_classes = targets.get_shape()[-1]\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.inference = None\n",
        "        self.loss = None\n",
        "        self.train_step = None\n",
        "        self.accuracy = None\n",
        "\n",
        "        self.make_inference()\n",
        "        self.make_loss()\n",
        "        self.make_train_step()\n",
        "        self.make_accuracy()\n",
        "\n",
        "    def make_inference(self):\n",
        "        if self.inference is None:\n",
        "\n",
        "            # Create LSTM cell\n",
        "            cell = tf.contrib.rnn.LSTMCell(self.hidden_size)\n",
        "\n",
        "            # Define the recurrent network\n",
        "            outputs, _ = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
        "\n",
        "            # Take the last output in the sequence\n",
        "            last_output = outputs[:, -1, :]\n",
        "\n",
        "            # Final dense layer to get to the prediction\n",
        "            self.inference = tf.layers.dense(last_output, self.n_classes, activation=tf.nn.softmax)\n",
        "\n",
        "    def make_loss(self):\n",
        "        # Build cross-entropy loss\n",
        "        if self.loss is None:\n",
        "            self.loss = - tf.reduce_sum(self.targets * tf.log(self.inference + epsilon))\n",
        "\n",
        "    def make_train_step(self):\n",
        "        # Define Optimizer and training step\n",
        "        if self.train_step is None:\n",
        "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "            self.train_step = optimizer.minimize(self.loss)\n",
        "\n",
        "    def make_accuracy(self):\n",
        "        if self.accuracy is None:\n",
        "            correct_predictions = tf.equal(tf.round(self.inference), targets)\n",
        "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RIpSR60_y4v2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training parameters"
      ]
    },
    {
      "metadata": {
        "id": "YZKaeAOtvoNK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 40\n",
        "batch_size = 128\n",
        "n_epochs = 3\n",
        "max_sequence_length = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z54M7WTgzC0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create and load the sequence dataset"
      ]
    },
    {
      "metadata": {
        "id": "L1NBHqfSvted",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "synthetic_dataset = SyntheticSequenceDataset(max_sequence_length=max_sequence_length)\n",
        "train_data, train_targets, test_data, test_targets = synthetic_dataset.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7rIUNMzzHyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create placeholders, input has shape=(None, sequence_length, 1), whereas targets have shape=(None, sequence_length+1)"
      ]
    },
    {
      "metadata": {
        "id": "-kGwD0oNvxNN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define placeholders\n",
        "data = tf.placeholder(dtype=tf.float32, shape=(None, max_sequence_length, 1))\n",
        "targets = tf.placeholder(dtype=tf.float32, shape=(None, max_sequence_length+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLnSx6Q3zTTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a DeepCounter model"
      ]
    },
    {
      "metadata": {
        "id": "2ApyAfq9xiBl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "deep_counter = DeepCounter(x=data, targets=targets, hidden_size=hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uujTFbUJzfnF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a session..."
      ]
    },
    {
      "metadata": {
        "id": "8Bek3qZuvzJ9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Open session\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nL0uLwGzWXH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and initialize variables"
      ]
    },
    {
      "metadata": {
        "id": "euOODtyHwF2t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGtvXoWxziZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training loop. Your role is to fill the code to run one optimization step"
      ]
    },
    {
      "metadata": {
        "id": "IW1i9m0zwKYF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batches_each_epoch = int(len(train_data)) // batch_size\n",
        "\n",
        "print('\\n' + 50*'*' + '\\nTraining\\n' + 50*'*')\n",
        "\n",
        "# Train batch by batch\n",
        "for epoch in range(0, n_epochs):\n",
        "\n",
        "    start_idx = 0\n",
        "    loss_current_epoch = []\n",
        "    for _ in range(0, batches_each_epoch):\n",
        "\n",
        "        # Load batch\n",
        "        end_idx = start_idx + batch_size\n",
        "        data_batch, target_batch = train_data[start_idx:end_idx], train_targets[start_idx:end_idx]\n",
        "\n",
        "        # Run one optimization step on current step\n",
        "        cur_loss, _ = sess.run([deep_counter.loss, deep_counter.train_step], feed_dict={data: data_batch, targets: target_batch})\n",
        "        loss_current_epoch.append(cur_loss)\n",
        "\n",
        "        # Update data pointer\n",
        "        start_idx += batch_size\n",
        "\n",
        "    print('Epoch {:02d} - Loss on train set: {:.02f}'.format(epoch, sum(loss_current_epoch)/batches_each_epoch))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdXbHggozuFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run test. Your role is to fill code to run the graph and compute accuracy"
      ]
    },
    {
      "metadata": {
        "id": "jlUYHrCtwMDN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n' + 50 * '*' + '\\nTesting\\n' + 50 * '*')\n",
        "\n",
        "accuracy_score = 0.0\n",
        "num_test_batches = int(len(test_data)) // batch_size\n",
        "start_idx = 0\n",
        "\n",
        "# Test batch by batch\n",
        "for _ in range(0, num_test_batches):\n",
        "    end_idx = start_idx + batch_size\n",
        "    data_batch, target_batch = test_data[start_idx:end_idx], test_targets[start_idx:end_idx]\n",
        "    # compute accuracy on batch\n",
        "    accuracy_score += sess.run(deep_counter.accuracy, feed_dict={data: data_batch, targets: target_batch})\n",
        "    start_idx += batch_size\n",
        "\n",
        "print('Average accuracy on test set: {:.03f}'.format(accuracy_score / num_test_batches))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DvF2hegY0Bqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Interactive section, just try to stress the model typing sequences yourself! :)"
      ]
    },
    {
      "metadata": {
        "id": "l6H0Fu-UwPu2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n' + 50 * '*' + '\\nInteractive Session\\n' + 50 * '*')\n",
        "\n",
        "while True:\n",
        "    my_sequence = raw_input('Write your own binary sequence 20 digits in {0, 1}:\\n')\n",
        "    if my_sequence:\n",
        "\n",
        "        # Pad shorter sequences\n",
        "        if len(my_sequence) < max_sequence_length:\n",
        "            my_sequence = (max_sequence_length - len(my_sequence))*'0' + my_sequence\n",
        "\n",
        "        # Crop longer sequences\n",
        "        my_sequence = my_sequence[:max_sequence_length]\n",
        "\n",
        "        # Prepare example\n",
        "        test_example = []\n",
        "        for binary_char in my_sequence:\n",
        "            test_example.append([float(binary_char)])\n",
        "\n",
        "        pred = sess.run(deep_counter.inference, feed_dict={data: np.expand_dims(test_example, 0)})\n",
        "        print('Predicted number of ones: {} - Real: {}\\n'.format(int(np.argmax(pred)), int(np.sum(test_example))))\n",
        "    else:\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
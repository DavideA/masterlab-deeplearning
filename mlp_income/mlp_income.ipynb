{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_income.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5PupPA_EhlVr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install package dependencies\n"
      ]
    },
    {
      "metadata": {
        "id": "9jQl1xeLvJMa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FeryZxbshqIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Include packages"
      ]
    },
    {
      "metadata": {
        "id": "3WW9oEOngoHN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from google_drive_downloader import GoogleDriveDownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iylDgFTShtA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code is necessary in order to read the Income dataset from csv files, and turn it into a numerical representation."
      ]
    },
    {
      "metadata": {
        "id": "C8hDaUvaup-p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "categoricals = {\n",
        "    'workclass': [\n",
        "        'Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov',\n",
        "        'State-gov', 'Without-pay', 'Never-worked', '?'\n",
        "    ],\n",
        "    'education': [\n",
        "        'Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school',\n",
        "        'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters',\n",
        "        '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool', '?'\n",
        "    ],\n",
        "    'marital_status': [\n",
        "        'Married-civ-spouse', 'Divorced', 'Never-married',\n",
        "        'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse', '?'\n",
        "    ],\n",
        "    'occupation': [\n",
        "        'Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial',\n",
        "        'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical',\n",
        "        'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces', '?'\n",
        "    ],\n",
        "    'relationship': ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried', '?'],\n",
        "    'race': ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black', '?'],\n",
        "    'sex': ['Female', 'Male', '?'],\n",
        "    'native_country': [\n",
        "        'United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany',\n",
        "        'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China',\n",
        "        'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica',\n",
        "        'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic',\n",
        "        'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala',\n",
        "        'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador',\n",
        "        'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands', '?'\n",
        "    ],\n",
        "    'income': ['<=50K', '>50K']\n",
        "}\n",
        "\n",
        "\n",
        "class Person(object):\n",
        "\n",
        "    def __init__(self, age, workclass, fnlwgt, education, education_num,\n",
        "                 marital_status, occupation, relationship, race, sex, capital_gain,\n",
        "                 capital_loss, hours_per_week, native_country, income):\n",
        "        self.age = int(age)\n",
        "        self.workclass = workclass\n",
        "        self.fnlwgt = int(fnlwgt)\n",
        "        self.education = education\n",
        "        self.education_num = int(education_num)\n",
        "        self.marital_status = marital_status\n",
        "        self.occupation = occupation\n",
        "        self.relationship = relationship\n",
        "        self.race = race\n",
        "        self.sex = sex\n",
        "        self.capital_gain = int(capital_gain)\n",
        "        self.capital_loss = int(capital_loss)\n",
        "        self.hours_per_week = int(hours_per_week)\n",
        "        self.native_country = native_country\n",
        "        self.income = income\n",
        "\n",
        "    @staticmethod\n",
        "    def to_categorical(key, value):\n",
        "        values = categoricals[key]\n",
        "        cat = np.zeros(shape=len(values))\n",
        "        cat[values.index(value)] = 1\n",
        "        return cat\n",
        "\n",
        "    @property\n",
        "    def to_numeric(self):\n",
        "        list = [[self.age],\n",
        "                self.to_categorical('workclass', self.workclass),\n",
        "                [self.fnlwgt],\n",
        "                self.to_categorical('education', self.education),\n",
        "                [self.education_num],\n",
        "                self.to_categorical('marital_status', self.marital_status),\n",
        "                self.to_categorical('occupation', self.occupation),\n",
        "                self.to_categorical('relationship', self.relationship),\n",
        "                self.to_categorical('race', self.race),\n",
        "                self.to_categorical('sex', self.sex),\n",
        "                [self.capital_gain],\n",
        "                [self.capital_loss],\n",
        "                [self.hours_per_week],\n",
        "                self.to_categorical('native_country', self.native_country),\n",
        "                self.to_categorical('income', self.income),\n",
        "                ]\n",
        "        return list\n",
        "\n",
        "GoogleDriveDownloader.download_file_from_google_drive(file_id='1Dr8ybk7vEFVdZzDi_YHkFoHSQQatqduS',\n",
        "                                                      dest_path='./income.zip',\n",
        "                                                      overwrite=True,\n",
        "                                                      unzip=True)\n",
        "\n",
        "\n",
        "def load_csv(csv_name):\n",
        "    with open(csv_name, 'rt') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "\n",
        "        samples = []\n",
        "        for row in csv_reader:\n",
        "            row = [s.strip() for s in row]\n",
        "            samples.append([item for sublist in Person(*row).to_numeric for item in sublist])\n",
        "\n",
        "    samples = np.stack(samples)\n",
        "    return samples\n",
        "\n",
        "\n",
        "def load_income_dataset():\n",
        "\n",
        "    train_samples = load_csv('income_train.csv')\n",
        "    test_samples = load_csv('income_test.csv')\n",
        "    x_train = train_samples[:, :-2]\n",
        "    y_train = train_samples[:, -2:]\n",
        "    x_test = test_samples[:, :-2]\n",
        "    y_test = test_samples[:, -2:]\n",
        "\n",
        "    x_train /= np.max(x_train + np.finfo(np.float32).eps, axis=0, keepdims=True)\n",
        "    x_test /= np.max(x_train + np.finfo(np.float32).eps, axis=0, keepdims=True)\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34MdEjzWh8UE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define some training parameters"
      ]
    },
    {
      "metadata": {
        "id": "l9p4yVRZhbFr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "batch_size = 64\n",
        "n_epochs = 100\n",
        "learning_rate = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRHYSppcieNV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actually load the Income dataset, splitted in training and testing."
      ]
    },
    {
      "metadata": {
        "id": "gTrdT5-niKAU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "x_train, y_train, x_test, y_test = load_income_dataset()\n",
        "\n",
        "n_train_samples, sample_dim = x_train.shape\n",
        "n_train_samples, n_classes = y_train.shape\n",
        "n_test_samples, sample_dim = x_test.shape\n",
        "n_test_samples, n_classes = y_test.shape\n",
        "\n",
        "print('Number of training examples: {}'.format(n_train_samples))\n",
        "print('Number of test examples: {}'.format(n_test_samples))\n",
        "print('Number of classes: {}'.format(n_classes))\n",
        "print('Number of features: {}'.format(sample_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aGzM-Wvik8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the placeholders for the input and the target. Can you guess the right shape? (Hint, they both have two dimensions)"
      ]
    },
    {
      "metadata": {
        "id": "UentbxmOi4HW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define placeholders (2-d)\n",
        "x = tf.placeholder(shape=(None, sample_dim), name='x', dtype=tf.float32)\n",
        "y = tf.placeholder(shape=(None, n_classes), name='y', dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVxq_vMOi8V0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the Multi-Layer Perceptron model, using [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)."
      ]
    },
    {
      "metadata": {
        "id": "BCpvAI2Gi7cM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Multi-layer perceptron\n",
        "h = tf.layers.dense(x, 512, activation=tf.nn.relu)\n",
        "h = tf.layers.dense(h, 512, activation=tf.nn.relu)\n",
        "h = tf.layers.dense(h, 512, activation=tf.nn.relu)\n",
        "h = tf.layers.dense(h, 512, activation=tf.nn.relu)\n",
        "h = tf.layers.dense(h, 512, activation=tf.nn.relu)\n",
        "h = tf.layers.dense(h, 256, activation=tf.nn.relu)\n",
        "y_pred = tf.layers.dense(h, n_classes, activation=tf.nn.softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-tmhobGPjSnK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a crossentropy loss function."
      ]
    },
    {
      "metadata": {
        "id": "0EcDY7kEjKDF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define objective function\n",
        "loss = - tf.reduce_mean(y * tf.log(y_pred + 0.00001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "onmJAzK0jaF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create an optimizer (see [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer))"
      ]
    },
    {
      "metadata": {
        "id": "jMLqP3JEjbKh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTJ4CCkojvz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the tensorflow operation for the training step."
      ]
    },
    {
      "metadata": {
        "id": "FdFKTHKZjunV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define one training iteration\n",
        "train_step = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWn6cLoVj6xs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model. This is usually implemented as a double loop over training epochs and batches. For each batch, perform one training step and print the loss function."
      ]
    },
    {
      "metadata": {
        "id": "1jE54ShVvYZe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    # Initialize all variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Number of batches per epoch\n",
        "    batches_per_epoch = n_train_samples // batch_size\n",
        "\n",
        "    # Train\n",
        "    for i in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        for b in range(0, batches_per_epoch):\n",
        "            # Get the b-th training batch\n",
        "            start = b*batch_size\n",
        "            end = (b+1)*batch_size\n",
        "            x_batch, y_batch = x_train[start:end], y_train[start:end]\n",
        "            \n",
        "            # Run the training operator and compute the loss feeding the batch\n",
        "            _, l = sess.run([train_step, loss], feed_dict={x: x_batch, y: y_batch})\n",
        "            \n",
        "            total_loss += l\n",
        "            \n",
        "        # Print mean loss among epoch\n",
        "        print('Epoch {0}: {1}'.format(i, total_loss / batches_per_epoch))\n",
        "        \n",
        "        \n",
        "    # Test?\n",
        "    correct_predictions = 0\n",
        "    for i in range(0, len(x_test)):\n",
        "        x_t, y_t = x_test[i:i+1], y_test[i:i+1]\n",
        "        y_p = sess.run(y_pred, feed_dict={x: x_t})\n",
        "        \n",
        "        correct_predictions += np.sum(np.round(y_p) * y_t)\n",
        "    print('Test accuracy: {}'.format(correct_predictions / len(x_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AHoCO3sudjMx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}